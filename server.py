from fastapi import FastAPI, WebSocket
from google import genai
from google.genai import types
import json
import os
from dotenv import load_dotenv
from vision_module import VisionModule  # å¯¼å…¥ Vision æ¨¡å—

# ----------------------------
# è¯»å– API Key
load_dotenv()
GENAI_API_KEY = os.getenv("GEMINI_API_KEY")
if not GENAI_API_KEY:
    raise ValueError("ğŸš¨ ERROR: æœªæ‰¾åˆ° GEMINI_API_KEYï¼Œè¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½®")

# ----------------------------
# åˆå§‹åŒ– Gemini Clientï¼ˆæ–°ç‰ˆç”¨æ³•ï¼‰
client = genai.Client(api_key=GENAI_API_KEY)

# ----------------------------
# é»˜è®¤æ¨¡å‹å‚æ•°å’Œç³»ç»Ÿæç¤º
DEFAULT_MODEL_CONFIG = {
    "temperature": 0.95,
    "max_output_tokens": 100,
    "top_p": 0.9,
    "top_k": 40
}
DEFAULT_SYSTEM_PROMPT = "ä½ æ˜¯ä¸€ä¸ªå¾ˆä¼šæ•´æ´»çš„VTuberï¼Œä¸ä½ çš„è§‚ä¼—äº’åŠ¨ï¼Œå¹¶æä¾›åå›æœ‰è¶£å›ç­”ã€‚å¯ä»¥ä¸­æ—¥è‹±è¿ç”¨ã€‚"

# ----------------------------
# å…±äº«é…ç½®æ¨¡å—ï¼ˆåŒæ—¶åŒ…å« Vision å’Œ æ–‡æœ¬ç”Ÿæˆç›¸å…³é…ç½®ï¼‰
class Config:
    vision_enabled: bool = False
    blink_frequency: float = 3.0
    vision_input_source: str = "camera"
    text_prompt: str = DEFAULT_SYSTEM_PROMPT
    model_config: dict = DEFAULT_MODEL_CONFIG.copy()

config = Config()

# ----------------------------
# åˆå§‹åŒ– Vision æ¨¡å—ï¼ˆå†…éƒ¨ä½¿ç”¨æœ€æ–°æ–‡æ¡£ç”¨æ³•ï¼‰
vision_module = VisionModule(api_key=GENAI_API_KEY)

app = FastAPI()

@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    await websocket.accept()
    print("âœ… Unity è¿æ¥æˆåŠŸï¼")
    try:
        while True:
            raw_data = await websocket.receive_text()
            print(f"ğŸ“© æ”¶åˆ° Unity æ¶ˆæ¯: {raw_data}")
            try:
                data = json.loads(raw_data)

                # 1. å®æ—¶æ–‡æœ¬è¾“å…¥ï¼šç”Ÿæˆæ–‡æœ¬å›å¤
                if "realtimeInput" in data:
                    user_input = data["realtimeInput"].get("text", "").strip()
                    if user_input:
                        print(f"ğŸ’¬ æ”¶åˆ°æ–‡æœ¬è¾“å…¥: {user_input}")
                        # å°†ç³»ç»Ÿ prompt ä¸ç”¨æˆ·è¾“å…¥ç»„åˆä¸ºæœ€ç»ˆæç¤º
                        final_prompt = config.text_prompt + "\n" + user_input
                        # è°ƒç”¨ Gemini æ–‡æœ¬ç”Ÿæˆ APIï¼Œä¼ å…¥è‡ªå®šä¹‰å‚æ•°ï¼ˆè‹¥æ”¯æŒï¼‰
                        response = client.models.generate_content(
                            model="gemini-2.0-flash",
                            contents=[final_prompt],
                            **config.model_config
                        )
                        text_response = response.text.strip() if response.text else "âš ï¸ AI æ²¡æœ‰è¿”å›æ–‡æœ¬"
                        await websocket.send_text(json.dumps({"response": text_response}))
                    else:
                        print("âš ï¸ ç©ºæ–‡æœ¬è¾“å…¥ï¼Œå¿½ç•¥")

                # 2. é…ç½®æ›´æ–°ï¼šå…è®¸æ›´æ–°è§†è§‰é…ç½®ã€æ–‡æœ¬æç¤ºåŠç”Ÿæˆå‚æ•°
                elif "configUpdate" in data:
                    update_data = data["configUpdate"]
                    config.vision_enabled = update_data.get("vision_enabled", config.vision_enabled)
                    config.blink_frequency = update_data.get("blink_frequency", config.blink_frequency)
                    config.vision_input_source = update_data.get("vision_input_source", config.vision_input_source)
                    if "text_prompt" in update_data:
                        config.text_prompt = update_data["text_prompt"]
                    if "model_config" in update_data:
                        # å…è®¸éƒ¨åˆ†æ›´æ–°å‚æ•°ï¼Œç¡®ä¿æ˜¯å­—å…¸ç±»å‹
                        config.model_config.update(update_data["model_config"])
                    print(f"ğŸ› ï¸ é…ç½®æ›´æ–°: vision_enabled={config.vision_enabled}, "
                          f"blink_frequency={config.blink_frequency}, "
                          f"vision_input_source={config.vision_input_source}, "
                          f"text_prompt={config.text_prompt}, model_config={config.model_config}")

                # 3. å¤„ç† Vision å›¾åƒæ•°æ®ï¼šè°ƒç”¨ Vision æ¨¡å—ç”Ÿæˆå›¾åƒæè¿°
                elif "image_data" in data:
                    image_data = data["image_data"]
                    vision_response = vision_module.process_image(image_data)
                    await websocket.send_text(json.dumps(vision_response))

                else:
                    print(f"â“ æ”¶åˆ°æœªçŸ¥æ¶ˆæ¯: {data}")

            except json.JSONDecodeError as e:
                print(f"âŒ JSONè§£æå¤±è´¥: {e}")

    except Exception as e:
        print(f"âŒ è¿æ¥å¼‚å¸¸å…³é—­: {e}")
    finally:
        await websocket.close()

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
